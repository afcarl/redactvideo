"from flask import Flask, Response, request, redirect, render_template, make_response\nfrom flask.ext.socketio import SocketIO, emit\nimport gevent\nimport rethinkdb as r\nimport re\napp = Flask(__name__)\napp.config['SECRET_KEY'] = 'secret!'\napp.config['PROPAGATE_EXCEPTIONS'] = True\nsocketio = SocketIO(app)\nimport json\nimport string\nimport random\nimport sendgrid\nimport hashlib\nfrom flask.ext.socketio import session as socket_session\nconn = r.connect( \"localhost\", 28015).repl()\ndb = r.db('redactvideodotorg')\nconn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\nprint conn\nimport boto\nimport boto.awslambda\n\nfrom boto.s3.connection import S3Connection\nfrom boto.s3.key import Key\nimport os,sys\nimport requests\nimport dlib\nimport glob\nfrom skimage import io\nfrom utils.video import put_folder_on_s3\nimport thread\n\nimport boto3\nimport random\nimport string\n\ndef id_generator(size=6, chars=string.ascii_uppercase + string.digits):\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    return ''.join(random.choice(chars) for _ in range(size))\n\n# Let's use Amazon S3\ns3 = boto3.resource('s3')\n\n# get settings\nbuckets = list(s3.buckets.all())\nsettings_buckets = [bucket.name for bucket in buckets if bucket.name.startswith('redactvideo_settings_')]\n\nif settings_buckets:\n    print \"There's a bucket\"\n    settings_bucket = settings_buckets[0]\nelse:\n    print \"There's not a bucket\"\n    bucket_name = 'redactvideo_settings_' + id_generator()\n    s3.create_bucket(Bucket=bucket_name)\ndef get_setting(setting):\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    try:\n        return db.table('settings').get(setting).run(conn)['value']   \n    except:\n        return ''    \n\n# Need to wait for RethinkDB to be running\n# in rc.local there's no wait between starting rethinkdb and\n# starting this script\nwhile True:\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    try:\n        s3conn = S3Connection(get_setting('access_key_id'), get_setting('secret_access_key'))\n        bucket = s3conn.get_bucket(get_setting('bucket_name'))\n        break\n    except:\n        pass\n\nfrom upload import upload_to_youtube\n\n\ndef is_logged_in(request):\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    if request.cookies.get('session'):\n        if Response(db.table('sessions').get(request.cookies.get('session')).run(conn)['userid']):\n            return True\n        else:\n            return False\n    else:\n        return False\n \ndef get_users_random_id(userid):\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    results = list(db.table('random_ids_for_users').filter({'userid': userid}).run(conn))\n    if results:\n        return results[0]['id']\n    else:\n        random_id = id_generator()\n        db.table('random_ids_for_users').insert({'id': random_id, 'userid': userid}).run(conn)\n        return random_id\n \n@app.route('/')\ndef index():\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    context = {}\n    context['google_analytics_tracking_id'] = get_setting('google_analytics_tracking_id')\n    if is_logged_in(request):\n        \n        user_id = db.table('sessions').get(request.cookies.get('session')).run(conn)['userid']\n        context['userid'] = user_id\n        context['users_random_id'] = get_users_random_id(user_id)\n        #print user_id\n        user_data = db.table('users').get(user_id).run(conn)\n        import base64\n        import hmac, hashlib\n        import random, string\n        policy_document = \"\"\"{\"expiration\": \"2020-01-01T00:00:00Z\",\n  \"conditions\": [ \n    {\"bucket\": \"%s\"}, \n    [\"starts-with\", \"$key\", \"%s/\"],\n    {\"acl\": \"public-read\"}\n  ]\n}\"\"\" % (get_setting('bucket_name'), user_id)\n        context['upload'] = {} \n        context['upload']['bucket_name'] = get_setting('bucket_name')\n        context['upload']['policy'] = base64.b64encode(policy_document)\n        context['upload']['access_key_id'] = get_setting('access_key_id')\n        context['upload']['signature'] = base64.b64encode(hmac.new(str(get_setting('secret_access_key')), context['upload']['policy'], hashlib.sha1).digest())\n        \n\n        rs = bucket.list(user_id)\n       \n        context['videos'] = [{'name': key.name[key.name.index('/')+1:], 'hash': get_md5(key.name)} for key in rs]\n        context['has_authed_with_youtube'] = True if user_data.get('youtube_refresh_token') else False\n        context['is_admin'] = user_data['is_admin']\n        context['google_client_id'] = get_setting('google_client_id')\n        if user_data['is_admin']:\n            context['site_settings'] = dict([(item['id'],item['value']) for item in db.table('settings').run(conn)])\n        if user_data.get('settings'):\n            context['user_settings'] = user_data['settings']\n        else:\n            context['user_settings'] = {'access_key_id': '', 'secret_access_key': ''}\n        return render_template('main.html', **context)\n        \n    elif db.table('users').count().run(conn) == 0:\n        return render_template('setup.html')\n    else:\n        return render_template('index.html', **context)\n\n@app.route('/convert_every_video_to_h264/', methods=['GET'])         \ndef convert_every_video_to_h264():\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    userid = db.table('sessions').get(request.cookies.get('session')).run(conn)['userid']\n    for video in bucket.list(userid):\n        \n        #print video, video.name\n        filename = video.name[video.name.index('/')+1:]\n        if not '@' in filename and filename.endswith('.MPG'):\n            continue\n        if not filename:\n            continue\n        video.get_contents_to_filename('/home/ubuntu/temp_videos/%s' % (filename))\n        os.system('ffmpeg -i \"/home/ubuntu/temp_videos/%s\" -y -r 24 -vcodec libx264 -preset ultrafast -b:a 32k -strict -2 \"/home/ubuntu/temp_videos/converted_%s.mp4\"' % (filename, filename[:-4]))\n        os.system('rm \"/home/ubuntu/temp_videos/%s\"' % (filename))\n        os.system('mv \"/home/ubuntu/temp_videos/converted_%s.mp4\" \"/home/ubuntu/temp_videos/%s.mp4\"' % (filename[:-4], filename[:-4]))\n        \n        upload_to_s3('/home/ubuntu/temp_videos/%s.mp4' % (filename[:-4]), userid)\n        os.system('rm \"/home/ubuntu/temp_videos/%s.mp4\"' % (filename[:-4]))\n    return Response('')\n\ndef get_md5(thestr):\n    import hashlib\n    m = hashlib.md5()\n    m.update(thestr)\n    return m.hexdigest()    \n    \n@app.route('/generate_thumbs_for_every_video/', methods=['GET'])         \ndef generate_thumbs_for_every_video():\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    from utils.video import put_folder_on_s3\n    userid = db.table('sessions').get(request.cookies.get('session')).run(conn)['userid']\n    for video in bucket.list(userid):\n        \n        #print video, video.name\n        filename = video.name[video.name.index('/')+1:]\n        if not filename:\n            continue\n        video.get_contents_to_filename('/home/ubuntu/temp_videos/%s' % (filename))\n        hash = get_md5(video.name)\n        os.system('mkdir /home/ubuntu/temp_videos/%s/' % (hash))\n        os.system('ffmpeg -i \"/home/ubuntu/temp_videos/%s\" -vf fps=1/30 /home/ubuntu/temp_videos/%s/%%03d.jpg' % (filename, hash))\n        put_folder_on_s3('/home/ubuntu/temp_videos/%s/' % (hash), hash, get_setting('bucket_name'), get_setting('access_key_id'), get_setting('secret_access_key'))\n        os.system('rm -rf /home/ubuntu/temp_videos/%s/' % (hash))\n    return Response('')\n    \n@app.route('/youtube_oauth_callback/', methods=['GET']) \ndef youtube_oauth_callback():\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    code = request.args['code']\n    t = requests.post(\n    'https://accounts.google.com/o/oauth2/token',\n    data={'code': code, 'client_id': get_setting('google_client_id'), 'client_secret': get_setting('google_client_secret'), 'redirect_uri': 'http://redactvideo.org/youtube_oauth_callback/', 'grant_type': 'authorization_code'})\n    data = t.json()\n    user_id = db.table('sessions').get(request.cookies.get('session')).run(conn)['userid']\n    db.table('users').get(user_id).update({'youtube_token': data['access_token'], 'youtube_refresh_token': data['refresh_token']}).run(conn)\n\n    \n    return render_template(\"youtube_callback.html\")        \n\ndef get_users_youtube_token(user_id):    \n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    youtube_refresh_token = db.table('users').get(user_id).run(conn)['youtube_refresh_token']\n    t = requests.post(\n    'https://accounts.google.com/o/oauth2/token',\n    data={'client_id': get_setting('google_client_id'), 'client_secret': get_setting('google_client_secret'), 'refresh_token': youtube_refresh_token, 'grant_type': 'refresh_token'})\n    data = t.json()\n    return data['access_token']\n    \n@app.route('/overblur_and_publish_all_videos/')\ndef overblur_and_publish_all_videos():\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    user_id = db.table('sessions').get(request.cookies.get('session')).run(conn)['userid']\n    youtube_token = get_users_youtube_token(user_id)\n    for key in bucket.list(user_id):\n        random_filename = id_generator()+'.mp4'\n        key.get_contents_to_filename('/home/ubuntu/temp_videos/%s' % (random_filename))\n        os.system('ffmpeg -threads 0 -i \"/home/ubuntu/temp_videos/%s\" -preset ultrafast -vf scale=320:240,\"boxblur=6:4:cr=2:ar=2\",format=yuv422p  -an \"/home/ubuntu/temp_videos/overredacted_%s\"' % (random_filename, random_filename))\n        upload_to_youtube('/home/ubuntu/temp_videos/overredacted_%s' % (random_filename), youtube_token)\n        os.remove('/home/ubuntu/temp_videos/%s' % (random_filename))\n        os.remove('/home/ubuntu/temp_videos/overredacted_%s' % (random_filename))\n    return Response('done')\n    \n@app.route('/change_site_settings/', methods=['POST'])\ndef change_site_settings():\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    if is_logged_in(request):\n        user_id = db.table('sessions').get(request.cookies.get('session')).run(conn)['userid']\n        user_data = db.table('users').get(user_id).run(conn)\n        if user_data['is_admin']: \n            settings = [{'id': item[0], 'value': item[1]} for item in request.form.items()]\n            db.table('settings').insert(settings, conflict='update').run(conn)\n            return Response(json.dumps({'success': True}))\n\n@app.route('/change_user_settings/', methods=['POST'])\ndef change_user_settings():\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    #print 'runns'\n    if is_logged_in(request):\n        user_id = db.table('sessions').get(request.cookies.get('session')).run(conn)['userid']\n        user_data = db.table('users').get(user_id).run(conn) \n        if user_data.get('settings'):\n            settings = user_data['settings']\n        else:\n            settings = {}\n        #print 'request data', dict(request.form)\n        # sometimes request.form is in the form of {'x': ['value']} instead of\n        # {'x': 'value'} so need to convert to\n        #  {'x': 'value'}\n        form = dict([(item[0], item[1] if isinstance(item[1], basestring) else item[1][0]) for item in request.form.items()])\n        settings.update(form)\n        #print 'settings', settings\n        db.table('users').get(user_id).update({'settings': settings}).run(conn)\n        #print db.table('users').get(user_id).run(conn)\n        return Response(json.dumps({'success': True}))            \n\n@app.route('/get_users_s3_buckets/', methods=['GET'])\ndef get_users_s3_buckets():\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    #print 'runns'\n    if is_logged_in(request):\n        user_id = db.table('sessions').get(request.cookies.get('session')).run(conn)['userid']\n        user_data = db.table('users').get(user_id).run(conn) \n        settings = user_data.get('settings')\n        s3conn_for_user = S3Connection(settings['access_key_id'], settings['secret_access_key'])\n        #s3conn_for_user.get_all_buckets()\n        return Response(json.dumps({'buckets': s3conn_for_user.get_all_buckets()}))   \n\n        \n@app.route('/logout/')        \ndef logout():\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    resp = make_response(redirect('/'))\n    resp.set_cookie('session', '', expires=0)\n    return resp\n        \n@app.route('/create_first_user/', methods=['POST'])\ndef create_first_user():\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    if db.table('users').count().run(conn) == 0:\n        email = request.form['email']\n        password = request.form['password']\n        salt = id_generator()\n        import hashlib\n        m = hashlib.sha512()\n        m.update(salt+password)\n        hash = m.hexdigest()\n        session_id = id_generator(30)\n        db.table('sessions').insert({'id': session_id, 'userid': email}).run(conn)\n        resp = make_response(redirect('/'))\n        resp.set_cookie('session', session_id)\n        db.table('users').insert({'id': email, 'salt': salt, 'hash': hash, 'is_admin': True}).run(conn)    \n        return resp\n    return redirect('/')\n\n@app.route('/login/', methods=['POST'])    \ndef login():\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    # it's assumed that a username is an email address\n    if not is_already_account(request.form['username']):\n        return Response(json.dumps({'msg': '<strong>Error:</strong> Either email or password is incorrect'}), mimetype=\"application/json\")\n    user_data = db.table('users').get(request.form['username']).run(conn)\n    m = hashlib.sha512()\n    salt = user_data['salt']\n    password = request.form['password']\n    m.update(salt+password)\n    hash = m.hexdigest()\n    \n    if user_data['hash'] != hash:\n        return Response(json.dumps({'msg': '<strong>Error:</strong> Either email or password is incorrect'}), mimetype=\"application/json\")\n    if not (user_data.get('is_approved') or user_data.get('is_admin')):\n        return Response(json.dumps({'msg': \"<strong>Error:</strong> Your account hasn't been approved\"}), mimetype=\"application/json\")\n    two_factor_code = id_generator(60)\n    db.table('two_factor_codes').insert({'id': two_factor_code, 'userid': request.form['username']}).run(conn)\n    message = sendgrid.Mail()\n    message.add_to(request.form['username'])\n    message.set_subject('RedactVideo two factor authentication')\n    message.set_html('<a href=\"http://redactvideo.org/confirm_two_factor/?two_factor_code=%s\">Click here</a> to confirm two factor code.' % (two_factor_code))\n    message.set_from('no-reply@redactvideo.org')\n    sg = sendgrid.SendGridClient(get_setting('sendgrid_username'), get_setting('sendgrid_password'))\n    status, msg = sg.send(message)\n    return Response(json.dumps({'msg': 'Two factor authentication email sent'}), mimetype=\"application/json\")\n\n\n@app.route('/confirm_two_factor/')            \ndef confirm_two_factor():\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    userid = db.table('two_factor_codes').get(request.args['two_factor_code']).run(conn)['userid']\n    user_data = db.table('users').get(userid).run(conn)\n    \n    session_id = id_generator(30)\n    username = userid\n    #print db.table('sessions').insert({'id': session_id, 'userid': username}).run(conn)\n    resp = make_response(redirect('/'))\n    resp.set_cookie('session', session_id)\n    return resp\n    \ndef is_already_account(email):\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    if list(db.table('users').filter({'id': email}).run(conn)):\n        return True\n    return False\n    \n    \n@app.route('/submit_request_for_account/', methods=['POST'])\ndef submit_request_for_account():\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    from validate_email import validate_email\n    if validate_email(request.form['agency_email'], check_mx=True): # verify=True didn't work\n        if is_already_account(request.form['agency_email']):\n            return Response(json.dumps({'success': False, 'msg': '<strong class=\"error\">Error:</strong> That email is already in the system'}), mimetype=\"application/json\")\n        else:\n            agency_email = request.form['agency_email']\n            message = sendgrid.Mail()\n            for admin in db.table('users').filter({'is_admin': True}).run(conn):\n                if '@' in admin['id']:\n                    message.add_to(admin['id'])\n            message.set_subject('%s requests RedactVideo account' % (agency_email))\n            message.set_html('%s is requesting an account' % (agency_email))\n            message.set_from('no-reply@redactvideo.org')\n            sg = sendgrid.SendGridClient(get_setting('sendgrid_username'), get_setting('sendgrid_password'))\n            status, msg = sg.send(message)\n            #print status, msg\n            secret_code = id_generator(60)\n            if agency_email.endswith('.gov'):\n                approved = True\n            else:\n                approved = None # None instead of False so we can tell when admin has made decision\n            db.table('accounts_to_verify').insert({'id': secret_code, 'userid': agency_email}, conflict='update').run(conn)\n            message = sendgrid.Mail()\n            message.add_to(agency_email)\n            message.set_subject('Confirm account for RedactVideo')\n            message.set_html('<a href=\"http://redactvideo.org/confirm_account/?code=%s\">Click here</a> to confirm your account.' % (secret_code))\n            message.set_from('no-reply@redactvideo.org')\n            sg = sendgrid.SendGridClient(get_setting('sendgrid_username'), get_setting('sendgrid_password'))\n            status, msg = sg.send(message)\n            db.table('users').insert({'id': agency_email, 'is_admin': False, 'verified': False, 'approved': approved}).run(conn)    \n            return Response(json.dumps({'success': True, 'msg': \"An email has been sent. Please click on the link in it to confirm your email.\"}), mimetype=\"application/json\")\n    else:\n        return Response(json.dumps({'success': False, 'msg': 'Invalid email address'}), mimetype=\"application/json\")\n\n@app.route('/confirm_account/')\ndef confirm_account():\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    userid = db.table('accounts_to_verify').get(request.args['code']).run(conn)['userid']\n    db.table('users').get(userid).update({'verified': True}).run(conn)  \n    session_id = id_generator(30)\n    username = userid\n    #print {'id': session_id, 'userid': username}\n    #print db.table('sessions').insert({'id': session_id, 'userid': username}).run(conn)\n    resp = make_response(render_template('create_password.html'))\n    resp.set_cookie('session', session_id)\n    return resp\n\n@app.route('/create_password/', methods=['POST'])    \ndef create_password():\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    #print request.form['retyped_password']\n    if request.form['password'] == request.form['retyped_password']:\n        user_id = db.table('sessions').get(request.cookies.get('session')).run(conn)['userid']\n        user_data = db.table('users').get(user_id).run(conn)\n        import hashlib\n        m = hashlib.sha512()\n        salt = id_generator()\n        m.update(salt+request.form['password'])\n        hash = m.hexdigest() \n        \n        \n        db.table('users').get(user_id).update({'salt': salt, 'hash': hash}).run(conn)  \n        return redirect('/')\n    else:\n        return redirect('/create_password/')\n\n@app.route('/autoupdate/', methods=['POST'])\ndef autoupdate():\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    github_signature = request.headers.get('X-Hub-Signature')\n    secret = get_setting('github_auto_update_secret')\n    import hmac\n    from hashlib import sha1\n    #print request.get_json()\n    #print secret\n    hmac_object = hmac.new(str(secret), request.data, digestmod=sha1)\n    if hmac.compare_digest(str(github_signature), 'sha1='+hmac_object.hexdigest()):\n        os.system('python autodeploy.py &')\n    return Response('')\n\ndef upload_to_s3(filepath, userid):\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    import math, os\n    import boto\n    from filechunkio import FileChunkIO\n\n    b = bucket\n\n    # Get file info\n    source_path = filepath\n    source_size = os.stat(source_path).st_size\n\n    # Create a multipart upload request\n    mp = b.initiate_multipart_upload(userid+'/'+os.path.basename(source_path))\n\n    # Use a chunk size of 50 MiB (feel free to change this)\n    chunk_size = 52428800\n    chunk_count = int(math.ceil(source_size / float(chunk_size)))\n\n    # Send the file parts, using FileChunkIO to create a file-like object\n    # that points to a certain byte range within the original file. We\n    # set bytes to never exceed the original file size.\n    for i in range(chunk_count):\n        offset = chunk_size * i\n        bytes = min(chunk_size, source_size - offset)\n        with FileChunkIO(source_path, 'r', offset=offset,\n                             bytes=bytes) as fp:\n            mp.upload_part_from_file(fp, part_num=i + 1)\n\n    # Finish the upload\n    mp.complete_upload()\n    key = bucket.get_key(userid+'/'+os.path.basename(source_path))\n    key.set_acl('public-read')\n\n@app.route('/save_upperbody_detection_coordinates/', methods=['POST'])\ndef save_upperbody():\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    import json\n    #print request.form\n    conn = r.connect( \"localhost\", 28015).repl()\n    db.table('upperbody_detections').insert({'id': request.form['filename'], 'coordinates': json.loads(request.form['detected_regions'])}, conflict='update').run(conn)\n    #print request.form\n    return Response('')\n\ndef send_short_email(userid, mes):    \n    message = sendgrid.Mail()\n    message.add_to(userid)\n    message.set_subject(mes)\n    message.set_html(mes)\n    message.set_from('no-reply@redactvideo.org')\n    sg = sendgrid.SendGridClient(get_setting('sendgrid_username'), get_setting('sendgrid_password'))\n    status, msg = sg.send(message)\n\ndef incoming_email_thread(form):\n    import rethinkdb as r\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    # parse the to email address\n    #print 'to', form['to']\n    if form['to'].endswith('>'):\n        m = re.search('\"(?P<email>.*)\"', form['to'])\n        email = m.group('email')\n    else:\n        email = form['to'].strip('\">')\n    if not email.endswith('@redactvideo.org'):\n        return Response('error')\n    userto = email.split('@')[0]\n    #print 'userto', userto\n    users_random_id = userto[:userto.index('_')].upper()\n    userid = db.table('random_ids_for_users').get(users_random_id).run(conn)['userid']\n    #print 'userid', userid\n    # download the evidence.com html with the url to download the zip file\n    #print 'txt is next'\n    #print form\n    body = form['html'] if 'html' in form else form['text']\n    m = re.search('(?P<base>https://(.*)\\.evidence\\.com)/1/uix/public/download/\\?package_id=(.*)ver=v2', body)\n    if not m:\n        #print 'something wrong with email parsing'\n        send_short_email(userid, 'Something wrong with the authenticated share make sure your share is unauthenticated')\n        #return Response('')\n    else:\n        print 'M', m\n    \n    r = requests.get(m.group(0))\n    \n    #print 'mgroup0', m.group(0)\n    base_url = m.group('base')\n    download_html = r.text\n    #print download_html\n    m = re.search('download_url=\"(?P<url>.*ver=v2)', download_html)\n    zip_download_url = base_url+m.group('url').replace('&amp;', '&')\n    \n    #print zip_download_url\n    # save the zip file\n    zips_id = id_generator()\n    with open('/home/ubuntu/temp_videos/'+zips_id+'.zip', 'wb') as handle:\n        response = requests.get(zip_download_url, stream=True)\n\n        if not response.ok:\n            pass\n\n        for block in response.iter_content(1024):\n            handle.write(block)\n    # unzip the file\n    #send_short_email(userid, 'Videos received from E.com now unpacking')\n    os.system('cd /home/ubuntu/temp_videos/; mkdir zips_id; unzip -d %s -j %s.zip' % (zips_id, zips_id))\n    #send_short_email(userid, 'Videos from E.com unpacked')\n    # now need to know what to do with the files\n    # e.g. put on S3 or on Youtube\n    if '_just_copy_over' in email:\n        for video in os.listdir('/home/ubuntu/temp_videos/'+zips_id):\n            if not video.endswith('pdf'):\n                upload_to_s3('/home/ubuntu/temp_videos/'+zips_id+'/'+video, userid)\n    elif 'as_is_to_' in email:\n        youtube_refresh_token = db.table('users').get(userid).run(conn)['youtube_refresh_token']\n        t = requests.post(\n        'https://accounts.google.com/o/oauth2/token',\n        data={'client_id': get_setting('google_client_id'), 'client_secret': get_setting('google_client_secret'), 'grant_type': 'refresh_token'})\n        data = t.json()\n        youtube_token = get_users_youtube_token(userid)\n        for video in os.listdir('/home/ubuntu/temp_videos/'+zips_id):\n            if not video.endswith('pdf'):\n                upload_to_youtube('/home/ubuntu/temp_videos/'+zips_id+'/'+video, youtube_token)\n    #elif 'overblur_to_youtube' in email:\n    else:    \n        youtube_refresh_token = db.table('users').get(userid).run(conn)['youtube_refresh_token']\n        t = requests.post(\n        'https://accounts.google.com/o/oauth2/token',\n        data={'client_id': get_setting('google_client_id'), 'client_secret': get_setting('google_client_secret'), 'grant_type': 'refresh_token'})\n        data = t.json()\n        youtube_token = get_users_youtube_token(userid)\n        for video in os.listdir('/home/ubuntu/temp_videos/'+zips_id):\n            if not video.endswith('pdf'): \n                os.system('ffmpeg -threads 0 -i \"/home/ubuntu/temp_videos/%s/%s\" -preset ultrafast -vf scale=320:240,\"boxblur=6:4:cr=2:ar=2\",format=yuv422p  -an \"/home/ubuntu/temp_videos/%s/overredacted_%s\"' % (zips_id, video, zips_id, video))\n                \n                upload_to_youtube('/home/ubuntu/temp_videos/'+zips_id+'/overredacted_'+video, youtube_token)\n                os.system('rm \"/home/ubuntu/temp_videos/'+zips_id+'/'+video+'\"')\n                os.system('rm \"/home/ubuntu/temp_videos/'+zips_id+'/overredacted_'+video+'\"')\n                \n                #send_short_email(userid, '%s overblured and uploaded to Youtube' % (video))\n                \n    os.system('rm -rf /home/ubuntu/temp_videos/'+zips_id)\n    #print 'from', form['from']\n    #return Response('')\n\n    \n@app.route('/incoming_email/', methods=['POST'])\ndef incoming_email():\n    thread.start_new_thread(incoming_email_thread, (request.form,))    \n    return Response('')\n    \n@socketio.on('message')\ndef handle_message(message):\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    #print message\n    send(message)\n\n@socketio.on('connect', namespace='/test')\ndef test_connect():\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    emit('my response', {'data': 'Connected'})\n\n@socketio.on('framize', namespace='/test')\ndef framize(message):\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    #print message['data']\n    video = message['data']\n    emit('framization_status', {'data': 'Downloading the video to framize'})\n    random_filename = get_md5(video)\n    emit('redaction_video_id', {'data': random_filename})\n    video_path = '/home/ubuntu/temp_videos/%s.mp4' % (random_filename)\n    target_dir = '/home/ubuntu/temp_videos/%s' % (random_filename)\n    if os.path.isdir(target_dir):\n        emit('framization_status', {'data': 'Already framized. Ready to redact.'})\n        \n        return\n    os.system('mkdir \"%s\"' % (target_dir))\n    bucket.get_key(video).get_contents_to_filename(video_path)\n    emit('framization_status', {'data': 'Starting framization'})\n    os.system('ffmpeg -i \"%s\" -y \"%s/%%08d.jpg\" 1>&- 2>&-  &' % (video_path, target_dir))\n    os.system('mkdir %s_contour' % (target_dir))\n    os.system('ffmpeg -i \"%s\" -y -preset ultrafast -vf \"edgedetect=low=0.25:high=0.5\",format=yuv422p -an %s' % (video_path, video_path[:-4]+'_contour.mp4'))\n    os.system('ffmpeg -i \"%s\" -y \"%s_contour/%%08d.jpg\"' % (video_path[:-4]+'_contour.mp4', target_dir))\n    #os.system('ffmpeg -i \"%s\" -y \"%s/%%08d.jpg\" &' % (video_path, target_dir))\n    \n    number_of_frames = os.popen(\"ffprobe -select_streams v -show_streams /home/ubuntu/temp_videos/%s.mp4 2>/dev/null | grep nb_frames | sed -e 's/nb_frames=//'\" % (random_filename)).read()\n    #print number_of_frames\n    number_of_frames = int(number_of_frames)\n    import time\n    while True:\n        number_of_files = len(os.listdir(target_dir))\n        percentage = '{0:.0%}'.format( float(number_of_files) / float(number_of_frames))\n        #print number_of_files, number_of_frames\n        #print 'Framizing. %s done' % (percentage) \n        emit('framization_status', {'data': 'Framizing. %s done' % (percentage)})\n        gevent.sleep(1) # see http://stackoverflow.com/questions/18941420/loop-seems-to-break-emit-events-inside-namespace-methods-gevent-socketio\n        if number_of_files >= number_of_frames:\n            break\n    \n    put_folder_on_s3(target_dir, random_filename+'_frames', get_setting('bucket_name'), get_setting('access_key_id'), get_setting('secret_access_key'))\n     \n    \ndef track_object(namespace, frames, start_rectangle, frame, box_id, direction, handle_head_to_side=True, throw_out_weirdness=True):\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    conn = r.connect( \"localhost\", 28015).repl()\n    db.table('track_status').insert({'id': box_id, 'stop': False}, conflict='update').run(conn) # this allows us to stop tracking from web interface \n    tracker = dlib.correlation_tracker()\n    positions = []\n    number_of_frames = len(frames)\n    last = None\n    \n    history = [[int(start_rectangle.left()), int(start_rectangle.top()), int(start_rectangle.width()), int(start_rectangle.height())]]\n    for k, f in enumerate(frames):\n        if db.table('track_status').get(box_id).run(conn)['stop']:\n            return\n        #print \"Processing Frame %s (%s)\" % (k, f)\n        #print f\n        img = io.imread(f)\n        \n        # We need to initialize the tracker on the first frame\n        if k == 0:\n            # Start a track on the juice box. If you look at the first frame you\n            # will see that the juice box is contained within the bounding\n            # box (74, 67, 112, 153).\n            if False:\n                left = start_rectangle.left() - 10\n                top =  start_rectangle.top() - 10\n                right = start_rectangle.right() + 10\n                bottom = start_rectangle.bottom() + 10\n                #print left, top, right, bottom\n                start_rectangle = dlib.rectangle(left, top, right, bottom)\n                #print [int(start_rectangle.left())-10, int(start_rectangle.top())-10, int(start_rectangle.width())+20, int(start_rectangle.height())+20]\n                #start_rectangle = dlib.rectangle(int(start_rectangle.left())-10, int(start_rectangle.top())-10, int(start_rectangle.width())+20, int(start_rectangle.height())+20)\n            tracker.start_track(img, start_rectangle)\n            percentage = r'0%'\n            namespace.emit('track_result', {'frame': frame + k, 'coordinates': history[0], 'box_id': box_id, 'percentage': percentage, 'direction': direction})\n        else:\n            # Else we just attempt to track from the previous frame\n            tracker.update(img)\n            position = tracker.get_position()\n            position = [int(position.left()), int(position.top()), int(position.width()), int(position.height())]\n            #position = [int(position.left())+10, int(position.top())+10, int(position.width())-20, int(position.height())-20]\n            #print 'last', last\n            how_far = 20\n            anomaly = 30\n            if handle_head_to_side:\n                if len(history) > (how_far + 2):\n                    #for i in range(0,2): # both horizontal (0) and vertical (1)\n                    for i in range(0,1): # just horizontal \n                        if (abs(position[i] - history[k-how_far][i])) > anomaly: # detect that box has moved significantly to the right \n                            if position[i] > history[k-how_far][i]:\n                                d = position[0 + i] - history[k-how_far][0 + i] + history[k-how_far][2] \n                            else:\n                                d = history[k-how_far][0 + i] - position[0 + i] + history[k-how_far][2] \n                            position = history[k-how_far]\n                            position[2 + i] = d\n                            for i in range(how_far):\n                                \n                                #print {'frame': frame + k - i, 'coordinates': position, 'box_id': box_id, 'percentage': percentage, 'direction': direction}\n                                namespace.emit('track_result', {'frame': frame + k - i, 'coordinates': position, 'box_id': box_id, 'percentage': percentage, 'direction': direction})\n                            left = int(position[0])\n                            top =  int(position[1])\n                            right = left + int(position[2])\n                            bottom = top + int(position[3])\n                            #print left, top, right, bottom\n                            if right > left and bottom > top:\n                                start_rectangle = dlib.rectangle(left, top, right, bottom)\n                                #print start_rectangle\n                                \n                                tracker = dlib.correlation_tracker()\n                                tracker.start_track(img, start_rectangle)\n                            \n            if throw_out_weirdness:\n                if last:\n                    throw_out = False\n                    for i, value in enumerate(last):\n                        #print 'abs', abs(value - position[i])\n                        if abs(value - position[i]) > 10: # helps ensure we don't go way off track have seen tracker go completely right of head when head goes to side\n                            position = last\n                            throw_out = True\n                            left = int(position[0])\n                            top =  int(position[1])\n                            right = left + int(position[2])\n                            bottom = top + int(position[3])\n                            start_rectangle = dlib.rectangle(left, top, right, bottom)\n                            tracker = dlib.correlation_tracker()\n                            tracker.start_track(img, start_rectangle)\n                            break\n                    if not throw_out:\n                        last = position                 \n                            \n                else:\n                    last = position\n            #last = position\n            #if k % 2 == 99:\n            if False:\n                left = int(position[0])-10\n                top =  int(position[1])-10\n                right = int(position[0]) + int(position[2]) + 10\n                bottom = int(position[1]) + int(position[3]) + 10\n                #print [left, top, right, bottom]\n                start_rectangle = dlib.rectangle(left, top, right, bottom)\n                tracker = dlib.correlation_tracker()\n                tracker.start_track(img, start_rectangle)\n                padding = 10*k\n                position = [position[0]+padding, position[1]+padding, position[2]-(2*padding), position[3]-(2*padding)]\n                #print 'MODIFIED POSITION', position\n            percentage = '{0:.0%}'.format( float(k) / float(number_of_frames))\n            if direction == 'backwards':\n                k = -1 * k\n            history.append(position)\n            \n            namespace.emit('track_result', {'frame': frame + k, 'coordinates': position, 'box_id': box_id, 'percentage': percentage, 'direction': direction})\n            #print position\n            #print dir(position)\n@socketio.on('track_forwards_and_backwards', namespace='/test')            \ndef track_forwards_and_backwards(message):\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    #print message \n    video_hash = get_md5(message['video_id'])\n    box_id = message['box_id']\n    #return\n    #video = message['data']\n    # Path to the video frames\n    video_folder = 'frames'\n\n    # Create the correlation tracker - the object needs to be initialized\n    # before it can be used\n    tracker = dlib.correlation_tracker()\n    positions = []\n    \n    # We will track the frames as we load them off of disk\n    frame = message['frame'] + 1\n    #if frame == 0:\n    #    frame = 1\n    total_frames = len(os.listdir('/home/ubuntu/temp_videos/%s/' % (video_hash)))\n    plusminusframes = 24 * 60 * 10 # ten minutes\n    if frame + plusminusframes < total_frames:\n        end = frame + plusminusframes\n    else:\n        end = total_frames\n    # remove later \n    end = total_frames\n    forward_frames = ['/home/ubuntu/temp_videos/%s_contour/%08d.jpg' % (video_hash, i) for i in range(frame, end)]\n    if frame - plusminusframes > 0:\n        end = frame - plusminusframes\n    else:\n        end = 0\n    end = 0 \n    backward_frames = ['/home/ubuntu/temp_videos/%s_contour/%08d.jpg' % (video_hash, i) for i in range(frame, end, -1) if i > 0]\n    #print forward_frames\n    #print frames\n    forward_positions = []\n    backward_positions = []\n    #print map(int,message['coordinates'])\n    c = message['coordinates']\n    start_rectangle = dlib.rectangle(c['left'], c['top'], c['right'], c['bottom'])\n    #print start_rectangle\n    import thread\n    #bbox = '%s,%s,%s,%s' % (c['left'], c['top'], c['right'] - c['left'], c['bottom'] - c['top'])\n    #print 'python ../CMT/run.py --quiet --no-preview --skip %s --bbox %s ../temp_videos/aba2eafda7e4e086fcab262c792e757e/{:08d}.jpg' % (frame, bbox)\n    #os.system('python ../CMT/run.py --quiet --no-preview --skip %s --bbox %s ../temp_videos/aba2eafda7e4e086fcab262c792e757e/{:08d}.jpg' % (frame, bbox))    \n    thread.start_new_thread(track_object, (request.namespace, forward_frames, start_rectangle, frame, box_id, 'forwards'))\n    thread.start_new_thread(track_object, (request.namespace, backward_frames, start_rectangle, frame, box_id, 'backwards'))\n    \n    #return HttpResponse(json.dumps({'backward_positions': backward_positions, 'forward_positions': forward_positions, 'max_width': max_width, 'max_height': max_height}), content_type='application/json')            \n\n@socketio.on('track_forwards', namespace='/test')            \ndef track_forwards(message):\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    #print message \n    video_hash = get_md5(message['video_id'])\n    box_id = message['box_id']\n    #return\n    #video = message['data']\n    # Path to the video frames\n    video_folder = 'frames'\n\n    # Create the correlation tracker - the object needs to be initialized\n    # before it can be used\n    tracker = dlib.correlation_tracker()\n    positions = []\n    \n    # We will track the frames as we load them off of disk\n    frame = message['frame']\n    if frame == 0:\n        frame = 1\n    total_frames = len(os.listdir('/home/ubuntu/temp_videos/%s/' % (video_hash)))\n    plusminusframes = 1800\n    if frame + plusminusframes < total_frames:\n        end = frame + plusminusframes\n    \n    else:\n        end = total_frames\n    end = total_frames-100\n    forward_frames = ['/home/ubuntu/temp_videos/%s/%08d.jpg' % (video_hash, i) for i in range(frame, end)]\n    \n    #print forward_frames\n    #print frames\n    forward_positions = []\n    backward_positions = []\n    #print map(int,message['coordinates'])\n    c = message['coordinates']\n    start_rectangle = dlib.rectangle(c['left'], c['top'], c['right'], c['bottom'])\n    #print start_rectangle\n    import thread\n     \n    thread.start_new_thread(track_object, (request.namespace, forward_frames, start_rectangle, frame, box_id, 'forwards'))\n\n@socketio.on('track_backwards', namespace='/test')            \ndef track_backwards(message):\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    #print message \n    video_hash = get_md5(message['video_id'])\n    box_id = message['box_id']\n    #return\n    #video = message['data']\n    # Path to the video frames\n    video_folder = 'frames'\n\n    # Create the correlation tracker - the object needs to be initialized\n    # before it can be used\n    tracker = dlib.correlation_tracker()\n    positions = []\n    \n    # We will track the frames as we load them off of disk\n    frame = message['frame']\n    if frame == 0:\n        frame = 1\n    total_frames = len(os.listdir('/home/ubuntu/temp_videos/%s/' % (video_hash)))\n    plusminusframes = 1800\n    \n    if frame - plusminusframes > 0:\n        end = frame - plusminusframes\n    else:\n        end = 0\n    end = 0\n    backward_frames = ['/home/ubuntu/temp_videos/%s/%08d.jpg' % (video_hash, i) for i in range(frame, end, -1) if i > 0]\n    \n    #print frames\n    forward_positions = []\n    backward_positions = []\n    #print map(int,message['coordinates'])\n    c = message['coordinates']\n    start_rectangle = dlib.rectangle(c['left'], c['top'], c['right'], c['bottom'])\n    #print start_rectangle\n    \n    thread.start_new_thread(track_object, (request.namespace, backward_frames, start_rectangle, frame, box_id, 'forwards'))\n\ndef generate_redacted_video_thread(namespace, message):\n    namespace.emit('framization_status', {'data': 'Generating redacted video'})\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    import cv2\n    coords = message['coordinates'] # coordinates are a dictionary of frame -> dictionary of box id -> coordinates\n    #print coords\n    video_hash = get_md5(message['video_id'])\n    os.system('rm -rf /home/ubuntu/temp_videos/redacted_%s' % (video_hash))\n    os.system('cp -r /home/ubuntu/temp_videos/%s /home/ubuntu/temp_videos/redacted_%s' % (video_hash, video_hash)) # we'll modify frames in the redacted folder\n    sorted(os.listdir('/home/ubuntu/temp_videos/redacted_%s' % (video_hash)))\n    frames = sorted(os.listdir('/home/ubuntu/temp_videos/redacted_%s' % (video_hash)))\n    number_of_frames = len(frames)\n    for i, frame in enumerate(frames):\n    #for i, frame in enumerate([]):\n        i += 1\n        percentage = '{0:.0%}'.format( float(i) / float(number_of_frames))\n        #print 'Framizing. %s done' % (percentage) \n        namespace.emit('framization_status', {'data': 'Applying redactions to each frame %s done' % (percentage)})\n        if not frame.endswith('.jpg'):\n            continue\n        frame = str(int(frame[:-4]))\n        #print frame\n        if frame in coords:\n            \n            filename = '/home/ubuntu/temp_videos/redacted_%s/%08d.jpg' % (video_hash, int(frame))\n            #print filename\n            img = cv2.imread(filename)\n            for c in coords[frame].values():\n                # c is left, top, width, height\n                x1 = c[0]\n                if x1 < 0:\n                    x1 = 0\n                if x1 > 720:\n                    x1 = 718\n                    \n                y1 = c[1] \n                if y1 < 0:\n                    y1 = 0\n                if y1 > 600:\n                    y1 = 558\n                x2 = x1 + c[2]\n                if x2 < 0:\n                    x2 = 0\n                if x2 > 720:\n                    x2 = 718\n                y2 = y1 + c[3]\n                if y2 < 0:\n                    y2 = 0\n                if y2 > 600:\n                    y2 = 558\n                cv2.rectangle(img, (x1, y1), (x2, y2), (0,0,0), -1) # -1 means fill\n            cv2.imwrite(filename,img)\n    namespace.emit('framization_status', {'data': 'Now merging the redacted frames into a video'})\n    os.system('ffmpeg -start_number 1 -i /home/ubuntu/temp_videos/redacted_%s/%%08d.jpg -y -r 24 -vcodec libx264 -preset ultrafast -b:a 32k -strict -2 /home/ubuntu/temp_videos/redacted_%s.mp4' % (video_hash, video_hash))\n    namespace.emit('framization_status', {'data': 'Video created'})\n    userid = message['video_id'][:message['video_id'].index('/')]\n    os.system('ffmpeg -i \"/home/ubuntu/temp_videos/%s.mp4\" -y -vn -acodec copy -b:a 32k -strict -2 /home/ubuntu/temp_videos/%s.aac' % (video_hash, video_hash))\n    audio_redactions = message['audio_redactions']\n    audio_redactions = ','.join([\"volume=enable='between(t,%s,%s)':volume=0\" % (ar['start'], ar['stop']) for ar in audio_redactions])\n    #print 'ffmpeg -i /home/ubuntu/temp_videos/%s.aac -y -af \"%s\" -b:a 32k -strict -2 /home/ubuntu/temp_videos/redacted_%s.aac' % (video_hash, audio_redactions, video_hash)\n    os.system('ffmpeg -i /home/ubuntu/temp_videos/%s.aac -y -af \"%s\" -b:a 32k -strict -2 /home/ubuntu/temp_videos/redacted_%s.aac' % (video_hash, audio_redactions, video_hash))\n    os.system('ffmpeg -i /home/ubuntu/temp_videos/redacted_%s.mp4 -i /home/ubuntu/temp_videos/redacted_%s.aac -y -r 24 -vcodec libx264 -preset ultrafast -b:a 32k -strict -2 /home/ubuntu/temp_videos/redacted_with_audio_%s.mp4' % (video_hash, video_hash, video_hash))\n    upload_to_s3('/home/ubuntu/temp_videos/redacted_with_audio_%s.mp4' % (video_hash), userid)\n    youtube_token = get_users_youtube_token(userid)\n    namespace.emit('framization_status', {'data': 'Uploaded', 'filename': '%s/redacted_with_audio_%s.mp4' % (userid, video_hash)})\n    upload_to_youtube('/home/ubuntu/temp_videos/redacted_with_audio_%s.mp4' % (video_hash), youtube_token)\n    namespace.emit('framization_status', {'data': 'Uploaded to Youtube'})    \n    \n@socketio.on('generate_redacted_video', namespace='/test') \ndef generate_redacted_video(message):\n    #print 'generate_redacted_video'     \n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    thread.start_new_thread(generate_redacted_video_thread, (request.namespace, message))          \n    \n@socketio.on('stop_tracking', namespace='/test')\ndef stop_tracking(message):\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    db.table('track_status').get(message['box_id']).update({'stop': True}).run(conn)\n\ndef do_detect_upper_body(namespace, video_id, start_frame):\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    # video_id should be userid/filename\n    video_hash = get_md5(video_id)\n    s3_prefix = get_md5(video_id)+'_frames'\n    total_frames = len(os.listdir('/home/ubuntu/temp_videos/%s/' % (video_hash)))\n    for i, frame in enumerate(range(start_frame, total_frames)):\n        \n        #if i > 10:\n        #    return\n        if i % 1800 == 0: # My AWS account is allotted 1,800 lambda functions running at one time running time is about 40 seconds to be safe wait 60 seconds\n            gevent.sleep(60)\n        # To ensure don't rack up huge bill because someone clicked over and over and over\n        filename = '%s_frames/%08d.jpg' % (video_hash, frame)\n        if db.table('upperbody_detections').get(filename).run(conn):\n            print 'already did upper body detection'\n            continue\n        lambdaConn = boto.connect_awslambda(get_setting('access_key_id'), get_setting('secret_access_key'), region=boto.awslambda.get_regions('awslambda')[0])\n        #print i, frame, lambdaConn.invoke_async('detectUpperBody', json.dumps({'filename': filename}))\n        \n    return \n\n@socketio.on('get_upper_body_detections', namespace='/test')\ndef get_upper_body_detections(message):\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    detections = db.table('upperbody_detections').run(conn)\n    detections = [(int(item['id'][item['id'].find('/')+1:item['id'].find('.')]), item['coordinates']) for item in detections if item['id'].startswith(message['video'])]\n    #print detections\n    for item in detections:\n        emit('upper_body_detections', {'frame': item[0], 'detections': item[1]})\n     \n    \n@socketio.on('detect_upper_body', namespace='/test')     \ndef detect_upper_body(message): \n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    #print 'facilitate_detect_upper_body'\n    #print message \n    thread.start_new_thread(do_detect_upper_body, (request.namespace, message['video_id'], message['start_frame']))\n\ndef gd(namespace, message):\n    import argparse\n    import datetime\n    import imutils\n    import time\n    import cv2\n    import numpy as np\n    import os\n         \n    firstFrame = None\n    detections = [[]]\n\n    # loop over the frames of the video\n    i = -1\n    grays = []\n    groups = {}\n    centers_to_groups = {}\n    group_i = 0\n    saved_frames = []\n    #print message['data']\n    video = message['data']\n    random_filename = get_md5(video)\n    video_path = '/home/ubuntu/temp_videos/%s.mp4' % (random_filename)\n    bucket.get_key(video).get_contents_to_filename(video_path)\n    camera = cv2.VideoCapture(video_path)\n    grays = []\n    # initialize the first frame in the video stream\n    firstFrame = None\n    avg = None\n    detections = [[]]\n    number_of_detections_per_frame = []\n    stopped_count = 0\n    started_count = 0\n    confirmed_stopped = False\n    import random\n    import string\n    #frames_folder = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(20))\n    #os.system('mkdir /home/ubuntu/temp_videos/%s/' % (frames_folder))\n    # loop over the frames of the video\n    while True:\n        #print i\n        i += 1\n        # grab the current frame and initialize the occupied/unoccupied\n        # text\n        (grabbed, frame) = camera.read()\n        text = \"Unoccupied\"\n\n        # if the frame could not be grabbed, then we have reached the end\n        # of the video\n        if not grabbed:\n            break\n\n        # resize the frame, convert it to grayscale, and blur it\n        #frame = imutils.resize(frame, width=500)\n        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n        gray = cv2.GaussianBlur(gray, (25, 25), 0)\n        \n        blurred = cv2.GaussianBlur(frame, (35, 35), 0)\n        \n        for j in range(2):\n            blurred = cv2.GaussianBlur(blurred, (35, 35), 0)\n        # if the first frame is None, initialize it\n        grays.append(gray)\n        if firstFrame is None:\n            firstFrame = gray\n        #    continue\n        #elif (i > 2 and not confirmed_stopped):\n        #    firstFrame = grays[i - 2]\n\n        # compute the absolute difference between the current frame and\n        # first frame\n        frameDelta = cv2.absdiff(firstFrame, gray)\n        #if avg is None:\n        #    #print \"[INFO] starting background model...\"\n        #    avg = gray.copy().astype(\"float\")\n        #    continue\n        #cv2.accumulateWeighted(gray, avg, 0.5)\n        #frameDelta = cv2.absdiff(gray, cv2.convertScaleAbs(avg))\n        thresh = cv2.threshold(frameDelta, 25, 255, cv2.THRESH_BINARY)[1]\n\n        # dilate the thresholded image to fill in holes, then find contours\n        # on thresholded image\n        thresh = cv2.dilate(thresh, None, iterations=10)\n        (cnts, _) = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n            cv2.CHAIN_APPROX_SIMPLE)\n        frames_detections = []\n        # loop over the contours\n        areas = []\n        new_centers_to_groups = {}\n        for c in cnts:\n            # compute the bounding box for the contour, draw it on the frame,\n            # and update the text\n            (x, y, w, h) = cv2.boundingRect(c)\n            #print w, h\n            #areas.append((w*h, w, h))\n            #detections.append(((x, y, w, h), i))\n            (x, y, w, h) = cv2.boundingRect(c)\n            center = (x + int(float(w)/2), y + int(float(h)/2))\n            frames_detections.append({'rect': (x, y, w, h), 'center': center})\n            \n            #print centers_to_groups\n            if i > 0:\n                for detection in detections[i-1]:\n                    (x2, y2, w2, h2) = detection['rect']\n                    center2 = detection['center']\n                    #center2 = (x + int(float(w)/2), y + int(float(h)/2))\n                    centers_close = abs(center2[0] - center[0]) < 50 and abs(center2[1] - center[1]) < 50\n                    corners_close = abs(x2 - x) < 20 or abs(y2 - y) < 20 or abs((x2 + w2) - (x + w)) < 20 or abs((y2 + h2) - (y + h)) < 20 \n                    area_close = abs((w2 * h2) - (w * h)) < 150\n                    size_close = True\n                    if w2 > w:\n                        if w / float(w2) < 0.33:\n                        \n                            size_close = False\n                    else:\n                        if w2 / float(w) < 0.33:\n                            size_close = False\n                    if h2 > h:\n                        if h / float(h2) < 0.33:\n                        \n                            size_close = False\n                    else:\n                        if h2 / float(h) < 0.33:\n                            size_close = False\n                    #if (centers_close or corners_close) and not size_close:\n                    #    #print \"size not close\"\n                    if (centers_close or corners_close) and size_close:\n                    #if centers_close:\n                    #if (centers_close or corners_close):\n                        #print 'true'\n                        #print i, (x, y, w, h), center, (x2, y2, w2, h2), center2\n                        if (x2, y2, w2, h2) in centers_to_groups:\n                            #print True, centers_to_groups[(x2, y2, w2, h2)]\n                            groups[centers_to_groups[(x2, y2, w2, h2)]].append(((x, y, w, h), center, i))\n                            #namespace.emit('background_subtraction_detection_group', {'group': centers_to_groups[(x2, y2, w2, h2)], 'coords': (x2, y2, w2, h2), 'frame': i})\n                            new_centers_to_groups[(x, y, w, h)] = centers_to_groups[(x2, y2, w2, h2)]\n                        else:\n                            groups[group_i] = [((x2, y2, w2, h2), center2, i-1), ((x, y, w, h), center, i)]\n                            namespace.emit('background_subtraction_detection_group', {'group': group_i, 'coordinates': (x2, y2, w2, h2), 'frame': i-1})\n                            #namespace.emit('background_subtraction_detection_group', {'group': group_i, 'coords': (x, y, w, h), 'frame': i})\n                            new_centers_to_groups[(x, y, w, h)] = group_i\n                            group_i += 1\n        if areas:\n            #print stopped_count\n            largest = sorted(areas, key=lambda x: x[0], reverse=True)[0]\n            #print largest[1], frame.shape[1]-120, largest[2], frame.shape[0]-120\n            if (largest[1] > frame.shape[1]-120 and largest[2] > frame.shape[0]-120):\n                #print 'yes'\n                firstFrame = gray\n        detections.append(frames_detections)\n        centers_to_groups = new_centers_to_groups.copy()    \n    \n@socketio.on('group_detections', namespace='/test')     \ndef group_detections(message):\n    thread.start_new_thread(gd, (request.namespace, message))\n\n            \n                \n                \n        \n@socketio.on('broadcast', namespace='/broadcast_everything')     \ndef broadcast(message):    \n    emit('broadcast', message, broadcast=True)\n\n@app.route('/broadcast_everything/', methods=['GET'])         \ndef broadcast_everything():\n    \n    return render_template('broadcast_everything.html')\n    \nif __name__ == '__main__':\n    socketio.run(app, host='0.0.0.0', port=80)"
{"patch":[[[[0," bucket."],[-1,"name."],[0,"startswi"]],1248,1248,21,16]],"time":1445653016029}
{"patch":[[[[0,"[bucket."],[-1,"name"],[0," for buc"]],1211,1211,20,16]],"time":1445653014030}
{"patch":[[[[0," [bucket"],[-1,"."],[0," for buc"]],1210,1210,17,16]],"time":1445653012034}
{"patch":[[[[0," not a bucke"],[-1,"t\""],[0,"\n    bucket_"]],1405,1405,26,24]],"time":1445652408490}
{"patch":[[[[0,"ere'"],[-1,"s not a bucke"],[0,"\n   "]],1400,1400,21,8]],"time":1445652406490}
{"patch":[[[[0,":\n    pr"],[-1,"int \"There'"],[0,"\n    buc"]],1385,1385,27,16]],"time":1445652404490}
{"patch":[[[[0,"se:\n"],[-1,"    pr\n"],[0,"    "]],1383,1383,15,8]],"time":1445652402491}
{"patch":[[[[0,"re's"],[-1," a bucket\""],[0,"\n   "]],1324,1324,18,8]],"time":1445652400489}
{"patch":[[[[0,"nt \""],[-1,"There's"],[0,"\n   "]],1317,1317,15,8]],"time":1445652398490}
{"patch":[[[[0,"  print "],[-1,"\""],[0,"\n    set"]],1312,1312,17,16]],"time":1445652396488}
{"patch":[[[[0,":\n    pr"],[-1,"int "],[0,"\n    set"]],1308,1308,20,16]],"time":1445652394486}
{"patch":[[[[0,"ts:\n    "],[-1,"pr"],[0,"\n    set"]],1306,1306,18,16]],"time":1445652392487}
{"patch":[[[[0,"uckets:\n"],[-1,"    \n"],[0,"    sett"]],1302,1302,21,16]],"time":1445652390489}
{"patch":[[[[0,"cket_nam"],[-1,"e"],[0,")\ndef ge"]],1447,1447,17,16]],"time":1445651688114}
{"patch":[[[[0,"et=bucke"],[-1,"t_nam"],[0,")\ndef ge"]],1442,1442,21,16]],"time":1445651686113}
{"patch":[[[[0,"Bucket=b"],[-1,"ucke"],[0,")\ndef ge"]],1438,1438,20,16]],"time":1445651684112}
{"patch":[[[[0,"(Bucket="],[-1,"b"],[1,"'mybucket'"],[0,")\ndef ge"]],1437,1437,17,26]],"time":1445651682113}
{"patch":[[[[0,"ttings_'"],[-1," +"],[0," id_gene"]],1391,1391,18,16]],"time":1445651678022}
{"patch":[[[[0,"ttings_'"],[-1," "],[0,"id_gener"]],1391,1391,17,16]],"time":1445651676022}
{"patch":[[[[0,"ettings_"],[-1,"'"],[0,"id_gener"]],1390,1390,17,16]],"time":1445651673321}
{"patch":[[[[0,"settings"],[-1,"_"],[0,"')]\n\nif "]],1275,1275,17,16]],"time":1445651668660}
{"patch":[[[[0,"edac"],[-1,"tvideo_settings_"],[0,"id_g"]],1377,1377,24,8]],"time":1445651664660}
{"patch":[[[[0," = 'reda"],[-1,"c"],[0,"id_gener"]],1372,1372,17,16]],"time":1445651662698}
{"patch":[[[[0," = 'reda"],[1,"ct_v"],[0,"id_gener"]],1372,1372,16,20]],"time":1445651655396}
{"patch":[[[[0,"edact_vi"],[1,"i"],[0,"d_genera"]],1377,1377,16,17]],"time":1445651653399}
{"patch":[[[[0,"edact_vi"],[1,"d"],[0,"id_gener"]],1377,1377,16,17]],"time":1445651651336}
{"patch":[[[[0,"dact_vid"],[1,"e"],[0,"id_gener"]],1378,1378,16,17]],"time":1445651647595}
{"patch":[[[[0,"'redact_"],[-1,"vide"],[0,"id_gener"]],1375,1375,20,16]],"time":1445651643804}
{"patch":[[[[0," 'redact"],[-1,"_"],[0,"id_gener"]],1374,1374,17,16]],"time":1445651641804}
{"patch":[[[[0," 'redact"],[1,"t"],[0,"id_gener"]],1374,1374,16,17]],"time":1445651639843}
{"patch":[[[[0," 'redact"],[-1,"t"],[0,"id_gener"]],1374,1374,17,16]],"time":1445651636786}
{"patch":[[[[0,"= 'redac"],[-1,"t"],[0,"id_gener"]],1373,1373,17,16]],"time":1445651634785}
{"patch":[[[[0,"name = '"],[-1,"redac"],[0,"id_gener"]],1368,1368,21,16]],"time":1445651632784}
{"patch":[[[[0,"_name = "],[-1,"'"],[0,"id_gener"]],1367,1367,17,16]],"time":1445651630784}
{"patch":[[[[0,"id_generator"],[-1,"()"],[0,"\n    s3.crea"]],1375,1375,26,24]],"time":1445651623567}
{"patch":[[[[0,"= id_gen"],[-1,"erator"],[0,"\n    s3."]],1373,1373,22,16]],"time":1445651621530}
{"patch":[[[[0,"ame = id"],[-1,"_gen"],[0,"\n    s3."]],1369,1369,20,16]],"time":1445651619530}
{"patch":[[[[0,"_name = "],[-1,"id"],[0,"\n    s3."]],1367,1367,18,16]],"time":1445651617530}
{"patch":[[[[0,"ng\n\n"],[-1,"def id_generator(size=6, chars=string.ascii_uppercase + string.digits):\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    return ''.join(random.choice(chars) for _ in range(size))"],[0,"\n\n# "]],874,874,223,8]],"time":1445651611955}
{"patch":[[[[0,"string\n\n"],[-1,"\n\n"],[0,"# Let's "]],870,870,18,16]],"time":1445651609955}
{"patch":[[[[0," string\n"],[-1,"\n"],[0,"# Let's "]],869,869,17,16]],"time":1445651607957}
{"patch":[[[[0,"youtube\n"],[1,"def id_generator(size=6, chars=string.ascii_uppercase + string.digits):\n    conn = r.connect( \"localhost\", 28015).repl(); db = r.db('redactvideodotorg');\n    return ''.join(random.choice(chars) for _ in range(size))"],[0,"\n\ndef is"]],1877,1877,16,231]],"time":1445651604707}
{"patch":[[[[0,"random\ni"],[-1,"mport string"],[0,"\n# Let's"]],856,856,28,16]],"time":1445651582310}
{"patch":[[[[0," random\n"],[-1,"i"],[0,"\n# Let's"]],855,855,17,16]],"time":1445651580311}
{"patch":[[[[0,"port ran"],[-1,"dom\n"],[0,"\n# Let's"]],851,851,20,16]],"time":1445651578309}
{"patch":[[[[0," boto3\ni"],[-1,"mport ran"],[0,"\n# Let's"]],842,842,25,16]],"time":1445651576309}
{"patch":[[[[0,"t boto3\n"],[-1,"i"],[0,"\n# Let's"]],841,841,17,16],[[[0,"t_name ="],[-1," "],[0,"\n    s3."]],1121,1121,17,16]],"time":1445651574310}
{"patch":[[[[0,"et_name "],[-1,"="],[0,"\n    s3."]],1120,1120,17,16]],"time":1445651572414}
{"patch":[[[[0," buc"],[-1,"ket_name "],[0,"\n   "]],1115,1115,17,8]],"time":1445651570289}
{"patch":[[[[0,"se:\n    "],[-1,"buc"],[0,"\n    s3."]],1108,1108,19,16]],"time":1445651568288}
{"patch":[[[[0,"]\nelse:\n"],[-1,"    \n"],[0,"    s3.c"]],1104,1104,21,16]],"time":1445651566287}
{"patch":[[[[0,"    "],[-1,"s3.create_bucket(Bucket='mybucket')"],[0,"\ndef"]],1112,1112,43,8]],"time":1445651562035}
{"patch":[[[[0,"ad\n\n"],[-1,"import boto3\n\n# Let's use Amazon S3\ns3 = boto3.resource('s3')\n"],[0,"\n# g"]],832,832,70,8]],"time":1445651446644}
{"patch":[[[[0,"thread\n\n"],[-1,"\n"],[0,"# get se"]],828,828,17,16]],"time":1445651444644}
{"patch":[[[[0,"slambda\n"],[-1,"\n"],[0,"from bot"]],622,622,17,16]],"time":1445651440955}
{"patch":[[[[0,"uckets[0"],[-1,"]"],[0,"\nelse:\n "]],1032,1032,17,16]],"time":1445651397686}
{"patch":[[[[0,"buckets["],[-1,"0"],[0,"\nelse:\n "]],1031,1031,17,16]],"time":1445651395689}
{"patch":[[[[0,"buckets["],[1,"   "],[0,"\nelse:\n "]],1031,1031,16,19]],"time":1445651389945}
{"patch":[[[[0,"kets[   "],[1," "],[0,"\nelse:\n "]],1034,1034,16,17]],"time":1445651388002}
{"patch":[[[[0,"_buc"],[-1,"kets["],[0,"    "]],1030,1030,13,8]],"time":1445651384756}
{"patch":[[[[0,"t = sett"],[-1,"ings_buc"],[0,"    \nels"]],1018,1018,24,16]],"time":1445651382755}
{"patch":[[[[0,"ucket = "],[-1,"sett"],[0,"    \nels"]],1014,1014,20,16]],"time":1445651380757}
{"patch":[[[[0,"ts:\n"],[-1,"    settings_bucket ="],[0,"    "]],996,996,29,8]],"time":1445651378759}
{"patch":[[[[0,"ts:\n    "],[-1," "],[0,"\nelse:\n "]],996,996,17,16]],"time":1445651376754}
{"patch":[[[[0,"ings')]\n"],[1,"settings_bucket = "],[0,"\nif sett"]],970,970,16,34]],"time":1445651374679}
{"patch":[[[[0,"ings_buc"],[-1,"ket = "],[0,"\nif sett"]],982,982,22,16]],"time":1445651371483}
{"patch":[[[[0,"settings"],[-1,"_buc"],[0,"\nif sett"]],978,978,20,16]],"time":1445651369482}
{"patch":[[[[0,"')]\nsett"],[-1,"ings"],[0,"\nif sett"]],974,974,20,16]],"time":1445651367482}
{"patch":[[[[0,"ings')]\n"],[-1,"sett"],[0,"\nif sett"]],970,970,20,16]],"time":1445651365483}
{"patch":[[[[0,"ings')]\n"],[-1,"\n"],[0,"if setti"]],970,970,17,16]],"time":1445651363519}
{"patch":[[[[0,"    \nels"],[-1,"e:\n    "],[0,"\ndef get"]],999,999,23,16]],"time":1445651354641}
{"patch":[[[[0,"s:\n    \n"],[-1,"els"],[1,"    "],[0,"\ndef get"]],996,996,19,20]],"time":1445651352641}
{"patch":[[[[0,"_buckets"],[-1,":\n    \n    "],[0,"\ndef get"]],989,989,27,16]],"time":1445651350638}
{"patch":[[[[0," setting"],[-1,"s_buckets"],[0,"\ndef get"]],980,980,25,16]],"time":1445651348638}
{"patch":[[[[0,")]\ni"],[-1,"f setting"],[0,"\ndef"]],975,975,17,8]],"time":1445651346636}
{"patch":[[[[0,"ings')]\n"],[-1,"i"],[0,"\ndef get"]],970,970,17,16]],"time":1445651344636}
{"patch":[[[[0,"\nset"],[-1,"tings_"],[0,"buck"]],882,882,14,8]],"time":1445651342637}
{"patch":[[[[0,".all())\n"],[-1,"set"],[0,"buckets "]],875,875,19,16]],"time":1445651340638}
{"patch":[[[[0,"\nbuckets"],[-1," = "],[0,"[bucket "]],882,882,19,16]],"time":1445651338674}
{"patch":[[[[0,"\nbuckets"],[1,"_starting_w"],[0,"[bucket "]],882,882,16,27]],"time":1445651336674}
{"patch":[[[[0,"starting"],[-1,"_w"],[0,"[bucket "]],891,891,18,16]],"time":1445651334635}
{"patch":[[[[0,"kets"],[-1,"_starting"],[0,"[buc"]],886,886,17,8]],"time":1445651332634}
{"patch":[[[[0,"all())\nb"],[-1,"uckets"],[0,"[bucket "]],876,876,22,16]],"time":1445651330635}
{"patch":[[[[0,".all())\n"],[-1,"b"],[0,"[bucket "]],875,875,17,16]],"time":1445651328633}
{"patch":[[[[0,"vide"],[-1,"o_settings"],[0,"')]\n"]],941,941,18,8]],"time":1445651318095}
{"patch":[[[[0,"swith('r"],[-1,"edactvide"],[0,"')]\n\ndef"]],928,928,25,16]],"time":1445651316094}
{"patch":[[[[0,"tswith('"],[-1,"r"],[0,"')]\n\ndef"]],927,927,17,16]],"time":1445651314094}
{"patch":[[[[0,"swith(''"],[-1,")]"],[0,"\n\ndef ge"]],928,928,18,16]],"time":1445651308193}
{"patch":[[[[0,"tswi"],[-1,"th(''"],[0,"\n\nde"]],927,927,13,8]],"time":1445651306191}
{"patch":[[[[0,"buck"],[-1,"et.startswi"],[0,"\n\nde"]],916,916,19,8]],"time":1445651304190}
{"patch":[[[[0,"buck"],[-1,"ets if buck"],[0,"\n\nde"]],905,905,19,8]],"time":1445651302187}
{"patch":[[[[0,"r bucket"],[-1," in buck"],[1,"s"],[0,"\n\ndef ge"]],893,893,24,17]],"time":1445651300187}
{"patch":[[[[0,"et f"],[-1,"or buckets"],[0,"\n\nde"]],888,888,18,8]],"time":1445651298184}
{"patch":[[[[0,"))\n["],[-1,"bucket f"],[0,"\n\nde"]],880,880,16,8]],"time":1445651296528}
{"patch":[[[[0,".all())\n"],[-1,"["],[1,"for bucket in buckets:\n    if bucket.starts"],[0,"\n\ndef ge"]],875,875,17,59]],"time":1445651294187}
{"patch":[[[[0,"et.start"],[-1,"s"],[0,"\n\ndef ge"]],917,917,17,16]],"time":1445651283242}
{"patch":[[[[0,"buck"],[-1,"et.start"],[0,"\n\nde"]],913,913,16,8]],"time":1445651281242}
{"patch":[[[[0,"    "],[-1,"if buck"],[0,"\n\nde"]],906,906,15,8]],"time":1445651279241}
{"patch":[[[[0," buckets"],[-1,":\n    "],[0,"\n\ndef ge"]],896,896,22,16]],"time":1445651277244}
{"patch":[[[[0,"cket in "],[-1,"buckets"],[0,"\n\ndef ge"]],889,889,23,16]],"time":1445651275242}
{"patch":[[[[0," buc"],[-1,"ket in "],[0,"\n\nde"]],886,886,15,8]],"time":1445651273240}
{"patch":[[[[0,"())\nfor "],[-1,"buc"],[0,"\n\ndef ge"]],879,879,19,16]],"time":1445651271240}
{"patch":[[[[0,".all())\n"],[1,"i"],[0,"f"],[-1,"or"],[0," \n\ndef g"]],875,875,19,18]],"time":1445651269242}
{"patch":[[[[0,"all())\ni"],[-1,"f "],[0,"\n\ndef ge"]],876,876,18,16]],"time":1445651267240}
{"patch":[[[[0,".all())\n"],[-1,"i"],[0,"\n\ndef ge"]],875,875,17,16]],"time":1445651265338}
{"patch":[[[[0,"all())\n\n"],[-1,"\n"],[0,"def get_"]],876,876,17,16]],"time":1445651262563}
{"patch":[[[[0,"ngs\n"],[-1,"buckets = list(s3.buckets.all())"],[0,"\n\nde"]],846,846,40,8]],"time":1445651260602}
{"patch":[[[[0," get set"],[-1,"tings\n"],[0,"\n\ndef ge"]],836,836,22,16]],"time":1445651258563}
{"patch":[[[[0,"\n\n# "],[-1,"get set"],[0,"\n\nde"]],833,833,15,8]],"time":1445651256562}
{"patch":[[[[0,"thread\n\n"],[-1,"# "],[0,"\n\ndef ge"]],827,827,18,16]],"time":1445651249957}
{"patch":[[[[0,"hread\n\n\n"],[-1,"\n"],[0,"def get_"]],828,828,17,16]],"time":1445651247945}
{"patch":[[[[0,"thread\n\n"],[-1,"\n"],[0,"def get_"]],827,827,17,16]],"time":1445651245949}
{"patch":[[[[0," = t.json()\n"],[1,"    #print data['access_token']\n"],[0,"    return d"]],8436,8436,24,56]],"time":1445296973250}
{"patch":[[[[0,"cess_token']"],[1," "],[0,"\n    \n@app.r"]],8499,8499,24,25]],"time":1445296969846}
{"patch":[[[[0,"token'] "],[1," "],[0,"\n    \n@a"]],8504,8504,16,17]],"time":1445296967888}
{"patch":[[[[0,"token'] "],[-1," "],[0,"\n    \n@a"]],8504,8504,17,16]],"time":1445294740764}
{"patch":[[[[0,"_token']"],[-1," "],[0,"\n    \n@a"]],8503,8503,17,16]],"time":1445294348435}